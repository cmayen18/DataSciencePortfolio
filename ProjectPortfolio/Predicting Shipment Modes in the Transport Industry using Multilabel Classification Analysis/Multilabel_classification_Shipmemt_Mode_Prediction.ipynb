{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rW7YkRt_I8n"
      },
      "source": [
        "# **Multilabel Classification Project for Predicting Shipment Modes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWu-7PKOBZTr"
      },
      "source": [
        "## **Project Overview**\n",
        "\n",
        "The transport industry is a critical component of the global economy. The efficient movement of goods is necessary to ensure that businesses can operate effectively and customers can receive their products on time. However, determining the appropriate mode of transport for each shipment can be challenging. It requires considering various factors such as the type of product being transported, the distance, and the destination.\n",
        "Choosing the appropriate mode of transport for each shipment can significantly affect the delivery time, cost, and safety of the goods being transported.\n",
        "\n",
        "For example, air transport is generally faster but more expensive than other modes, while sea transport is slower but more cost-effective for large shipments. The wrong choice of transport mode can result in delays, damage to the goods, or increased costs for the business. By accurately predicting the appropriate mode of transport for each shipment, businesses can optimize their logistics operations, reduce costs, and improve customer satisfaction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQodg9CYA-q9"
      },
      "source": [
        "![image](https://images.unsplash.com/photo-1578575437130-527eed3abbec?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1170&q=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgnQa4r_BhEq"
      },
      "source": [
        "To build the machine learning model, we first explore the dataset using BigQuery. We will implement four different approaches to multilabel classification:\n",
        "\n",
        "Naive independent models - We will build independent models for each label and combine the predictions to determine the appropriate mode of transport.\n",
        "\n",
        "Classifier chains - We will use a chain of classifiers, where the output of one classifier is fed into the next classifier to predict the labels. \n",
        "\n",
        "\n",
        "Natively multilabel models - We will use models designed to handle multilabel classification tasks, such as Extra Trees and Neural Networks.\n",
        "\n",
        "Multilabel to multiclass approach - We will convert the multilabel problem into a multiclass problem by combining different combinations of labels and training the model to predict these combinations. After prediction, we will separate the combinations back into individual labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-XDxYWOBz2F"
      },
      "source": [
        "## **Learning Outcomes**\n",
        "\n",
        "* Understanding the importance of predicting the appropriate mode of transport for each shipment in the transport industry.\n",
        "\n",
        "* Exploring a multilabel classification problem statement.\n",
        "Understanding the four different approaches to multilabel classification.\n",
        "\n",
        "* Querying and exploring the dataset using BigQuery.\n",
        "\n",
        "* Preprocessing and cleaning the dataset using GCP Big Query\n",
        "\n",
        "* Feature selection and engineering using domain knowledge.\n",
        "\n",
        "* Implementing naive independent models for each label and evaluating the results.\n",
        "\n",
        "* Implementing classifier chains for multilabel classification and evaluating the results.\n",
        "\n",
        "* Implementing natively multilabel models, such as Extra Trees and Neural Networks, and evaluating the results.\n",
        "\n",
        "* Implementing the multilabel to multiclass approach and evaluating the results.\n",
        "Comparing and contrasting the results of each approach.\n",
        "\n",
        "* Understanding the trade-offs and limitations of each approach.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUdE_lfvCQ3R"
      },
      "source": [
        "## **Who is this notebook intended for?**\n",
        " \n",
        "This notebook is intended for anyone interested in learning about multilabel classification and its applications in the transport industry. It is designed for beginners who have a basic understanding of machine learning and are looking to expand their knowledge. This notebook will provide a step-by-step approach to multilabel classification using four different approaches, making it ideal for learners to gain practical experience in multilabel classification. \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "![student](https://img.freepik.com/premium-vector/man-working-with-laptop-cartoon-illustration-labour-day-concept-white-isolated-flat-cartoon-style_75802-203.jpg?w=400)\n",
        "\n",
        "The notebook provides clear explanations of the concepts and techniques used, making it accessible to anyone interested in learning about this topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0h1WLj1ChkU"
      },
      "source": [
        "#### **We highly recommend watching the project videos for better understanding.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqkahc5qGb5V"
      },
      "source": [
        "## **Execution Instructions**\n",
        "<br>\n",
        " \n",
        "### Option 1: Running on your computer locally\n",
        " \n",
        "To run the notebook on your local system set up a [python](https://www.python.org/) environment. Set up the [jupyter notebook](https://jupyter.org/install) with python or by using [anaconda distribution](https://anaconda.org/anaconda/jupyter). Download the notebook and open a jupyter notebook to run the code on local system.\n",
        " \n",
        "The notebook can also be executed by using [Visual Studio Code](https://code.visualstudio.com/), and [PyCharm](https://www.jetbrains.com/pycharm/).\n",
        "<br>\n",
        "<br>\n",
        " \n",
        "\n",
        " \n",
        "### Option 2: Executing with Colab\n",
        "Colab, or \"Collaboratory\", allows you to write and execute Python in your browser, with access to GPUs free of charge and easy sharing.\n",
        " \n",
        "You can run the code using [Google Colab](https://colab.research.google.com/) by uploading the ipython notebook. \n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5S9NNgOG9bE"
      },
      "source": [
        "##  **Approach**\n",
        "\n",
        "* Exploratory Data Analysis (EDA):\n",
        "  * Understand the features\n",
        "  * Check the data summary\n",
        "  * Check for missing or invalid values\n",
        "\n",
        "* Preprocessing:\n",
        "  * Encoding the categorical features\n",
        "  * Split the dataset into training and testing sets\n",
        "\n",
        "\n",
        "* Create cross-validation sets\n",
        "\n",
        "* Multilabel Classification:\n",
        "\n",
        "  * Approach 0 - Naive Independent Models:\n",
        "    * Train separate binary classifiers for each target label-lightgbm\n",
        "    * Predict the label \n",
        "    * Evaluate model performance using the f1 score\n",
        "  * Approach 1 - Classifier Chains:\n",
        "    * Train a binary classifier for each target label\n",
        "    * Chain the classifiers together to consider the dependencies between labels\n",
        "    * Predict the label \n",
        "    * Evaluate model performance using the f1 score\n",
        "  * Approach 2 - Natively Multilabel Models:\n",
        "    * Train models that can natively handle multiple labels\n",
        "    * Use models such as Extra Trees and Neural Networks\n",
        "    * Evaluate model performance using the f1 score\n",
        "  * Approach 3 - Multilabel to Multiclass Approach:\n",
        "    * Combine different combinations of labels into a single target label\n",
        "    * Train a lightgbm classifier on the combined labels\n",
        "    * Evaluate model performance using f1 score, precision, and recall\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93LLrAvFDvYD"
      },
      "source": [
        "## **Data Reading with GCP BigQuery**\n",
        "\n",
        "Cloud computing has revolutionized the way data is stored, processed, and analyzed. Google Cloud Platform (GCP) provides a suite of tools and services that allow us to manage and analyze large datasets efficiently. One of the most powerful tools provided by GCP is BigQuery, a serverless, highly-scalable, and cost-effective data warehouse that can process and analyze petabyte-scale datasets in real-time. In this project, we will be using BigQuery to read, process, and prepare the data for machine learning modeling. Using BigQuery eliminates the need for setting up a traditional database management system or writing complex code for data processing. By leveraging BigQuery, we can quickly preprocess large datasets and transform them into a format suitable for machine learning models.\n",
        "\n",
        "\n",
        "To run the project, it is necessary to create a BigQuery table from the CSV file provided in the code folder by uploading it to Cloud Storage. Once the table is created, we can read it using the BigQuery API in Python. To do this, we need to authenticate our email ID and change the project ID in the read_gbq function to the name of the project we saved the table in.\n",
        "\n",
        "\n",
        "### **Creating a Bucket in Google Cloud Storage**\n",
        "\n",
        "* To create a bucket in Google Cloud Storage and upload a CSV file into it, you can follow these steps:\n",
        "\n",
        "* Open the Google Cloud Console and select the project that you want to work with.\n",
        "\n",
        "* In the left pane, select \"Storage\" and then \"Storage Browser\".\n",
        "\n",
        "* Click on the \"Create Bucket\" button.\n",
        "\n",
        "* In the \"Create Bucket\" dialog box, specify the name of the bucket, choose a location for the bucket, and select the default storage class for the bucket.\n",
        "\n",
        "* Click on the \"Create\" button to create the bucket.\n",
        "\n",
        "* Once the bucket is created, select it in the Storage Browser.\n",
        "\n",
        "* Click on the \"Upload Files\" button.\n",
        "\n",
        "* In the \"Upload Files\" dialog box, select the CSV file that you want to upload and click on the \"Open\" button.\n",
        "\n",
        "* Wait for the upload to complete. Once it is finished, you should see the CSV file listed in the bucket in the Storage Browser.\n",
        "\n",
        "\n",
        "### **Creating a Dataset in BigQuery with a CSV stored in Cloud Storage**\n",
        "\n",
        "* To create a table in BigQuery from a CSV file stored in Cloud Storage, you can follow these steps:\n",
        "\n",
        "* Open the BigQuery web console in the Google Cloud Console.\n",
        "\n",
        "* Select the project that you want to work with.\n",
        "\n",
        "* In the left pane, select the dataset where you want to create the table.\n",
        "\n",
        "* Click on the \"Create Table\" button.\n",
        "\n",
        "* In the \"Create Table\" dialog box, select \"Google Cloud Storage\" as the \"Source\".\n",
        "\n",
        "* Specify the location of your CSV file in Cloud Storage, either by typing the path or using the file picker.\n",
        "\n",
        "* In the \"Schema\" section, define the structure of your table by specifying the column names, data types, and any additional properties.\n",
        "\n",
        "* Click on the \"Create Table\" button to create the table.\n",
        "\n",
        "* BigQuery will automatically load the data from the CSV file into the newly created table.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r9h2DLUCUs5"
      },
      "source": [
        "## **Important Libraries**\n",
        "\n",
        "\n",
        "* **google-cloud-bigquery**: Google Cloud BigQuery is a fully-managed, serverless data warehouse that enables super-fast SQL queries using the processing power of Google's infrastructure. The google-cloud-bigquery Python library makes it easy to interact with BigQuery API. Refer to [documentation](http://gcloud.readthedocs.io/en/latest/bigquery-client.html) for more information.\n",
        "\n",
        "\n",
        "* **pandas**: pandas is a fast, powerful, flexible, and easy-to-use open-source data analysis and manipulation tool built on top of the Python programming language. Refer to [documentation](https://pandas.pydata.org/) for more information.\n",
        "\n",
        "* **pandas_gbq**: pandas_gbq is a Python package that provides a convenient interface to Google BigQuery, allowing you to query tables, write results to tables, and manage metadata. Refer to [documentation](https://pandas-gbq.readthedocs.io/) for more information.\n",
        "\n",
        "* **numpy**: The fundamental package for scientific computing with Python. Fast and versatile, the NumPy vectorization, indexing, and broadcasting concepts are the de-facto standards of array computing today. NumPy offers comprehensive mathematical functions, random number generators, linear algebra routines, Fourier transforms, and more. Refer to [documentation](https://numpy.org/) for more information.\n",
        "\n",
        "* **Matplotlib**: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. Refer to [documentation](https://matplotlib.org/) for more information.\n",
        "\n",
        "* **scikit-learn**: Simple and efficient tools for predictive data analysis\n",
        "accessible to everybody and reusable in various contexts.\n",
        "It is built on NumPy, SciPy, and matplotlib to support machine learning in Python. Refer to [documentation](https://scikit-learn.org/stable/) for more information.\n",
        "\n",
        "* **lightgbm**: LightGBM is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be efficient, scalable, and portable. Refer to [documentation](https://lightgbm.readthedocs.io/en/latest/) for more information.\n",
        "\n",
        "* **tensorflow**: TensorFlow is a free and open-source software library for machine learning and artificial intelligence. It can be used across a range of tasks but has a particular focus on training and inference of deep neural networks. Refer to [documentation](https://www.tensorflow.org/api_docs) for more information.\n",
        "\n",
        "* **keras**: Keras is an open-source software library that provides a Python interface for the TensorFlow deep learning framework. It is designed to enable fast experimentation with deep neural networks, and it focuses on being user-friendly, modular, and extensible. Refer to [documentation](https://keras.io/) for more information.\n",
        "\n",
        "* **tensorflow-addons**: TensorFlow Addons is a repository of contributions that extend the functionality of TensorFlow. It includes a number of libraries for advanced feature engineering, neural architecture search, metrics and losses, and more. Refer to [documentation](https://www.tensorflow.org/addons/overview) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9HUphxqGkKU"
      },
      "source": [
        "## **Install Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9Yce8zNuH6q"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcHAAL0tGjZy",
        "outputId": "5c89b330-a6d3-4ccf-b63b-2a01312e0e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/591.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/591.0 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-bigquery==3.9.0\n",
        "!pip install pandas==1.4.4\n",
        "!pip install pandas_gbq==0.17.9\n",
        "!pip install numpy==1.22.4\n",
        "!pip install projectpro --upgrade\n",
        "!pip install matplotlib==3.7.1\n",
        "!pip install scikit-learn==1.2.2\n",
        "!pip install lightgbm==3.3.5\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install keras==2.12.0\n",
        "!pip install tensorflow-addons==0.20.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISN04RKjhk1l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from projectpro import preserve, model_snapshot\n",
        "from pandas.io import gbq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poSr1U_iIYi0"
      },
      "source": [
        "## **Authentication**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eLbMgLq-BYY"
      },
      "source": [
        "### **Authentication using Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZR0eOhIhykN"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pydrive.auth import GoogleAuth\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apcfro26-FPj"
      },
      "source": [
        "### **Authentication using Local System**\n",
        "\n",
        "Once you have created the BigQuery table and added a service account (permissions access to an email id),\n",
        "you can download the GOOGLE_APPLICATION_CREDENTIALS JSON file from the Google Cloud Console.\n",
        "\n",
        "Here's how you can download it:\n",
        "\n",
        "* Go to the Google Cloud Console.\n",
        "* Select your project and go to the \"IAM & admin\" section from the left sidebar.\n",
        "* Click on \"Service accounts\".\n",
        "* Create a new service account or select an existing one.\n",
        "* Click on \"Create key\" and select \"JSON\" as the key type.\n",
        "* Save the JSON file to your local machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-_a4aob_hqq"
      },
      "source": [
        "**Note**: The notebook code has been developed according to Google Colab authentication, which requires the file to be uploaded to Google Drive and opened with Colab to run it. If you want to run it on a local system, you need to provide the necessary credentials while sending the query `gbq.read_gbq(query=query, project_id=project_id, credentials=credentials)`, where credentials is the JSON access key.\n",
        "\n",
        "Here's the code demonstrating the above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVDG2Ee2-K7L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../empirical-realm-374307-8bbebe57ceef.json'\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "# Path to the service account key file\n",
        "key_path = '../empirical-realm-374307-8bbebe57ceef.json'\n",
        "\n",
        "# Set up the credentials object\n",
        "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
        "\n",
        "# Set the project ID\n",
        "project_id = 'empirical-realm-374307'\n",
        "\n",
        "# Set the SQL query\n",
        "query = \"\"\"SELECT * FROM `empirical-realm-374307.transport_dataset.product_transport` LIMIT 10\"\"\"\n",
        "\n",
        "# Use pandas to execute the query and load the results into a DataFrame\n",
        "df = gbq.read_gbq(query=query, project_id=project_id, credentials=credentials)\n",
        "\n",
        "# Print the DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCVvyTVzISIn"
      },
      "source": [
        "## **Data Exploration and Processing**\n",
        "\n",
        "Data exploration and processing are crucial steps in any machine learning project. In this project, we explore and preprocess the dataset using GCP BigQuery, which allows us to query large datasets quickly and efficiently. We use SQL queries to get a better understanding of the data, identify any missing values, and select relevant features for our model.\n",
        "\n",
        "\n",
        "The SQL query` \"SELECT * FROM empirical-realm-374307.transport_dataset.product_transport LIMIT 10\"` retrieves the first 10 rows of data from the table product_transport in the transport_dataset dataset of the `empirical-realm-374307` project in Google BigQuery.\n",
        "\n",
        "Here is a brief explanation of the SQL functions used in this query:\n",
        "\n",
        "* SELECT: This function is used to specify the columns that you want to retrieve from a table. The asterisk (*) is a wildcard that selects all columns.\n",
        "\n",
        "* FROM: This function is used to specify the table that you want to retrieve data from.\n",
        "empirical-realm-374307.transport_dataset.product_transport: This is the fully qualified name of the table in the format project_id.dataset_id.table_id. \n",
        "\n",
        "* LIMIT: This function is used to limit the number of rows that are returned by a query. In this case, it limits the results to the first 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "fP1jN4rbilnr",
        "outputId": "a4053ede-0c56-4d60-863e-070760166fe1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dfb7ad58-48a7-4f37-8b16-9472321e6974\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product_Id</th>\n",
              "      <th>Net_Weight</th>\n",
              "      <th>Size</th>\n",
              "      <th>Value</th>\n",
              "      <th>Storage</th>\n",
              "      <th>Packaging_Cost</th>\n",
              "      <th>Expiry_Period</th>\n",
              "      <th>Length</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Perishable_Index</th>\n",
              "      <th>Flammability_Index</th>\n",
              "      <th>F145</th>\n",
              "      <th>F7987</th>\n",
              "      <th>F992</th>\n",
              "      <th>Air</th>\n",
              "      <th>Road</th>\n",
              "      <th>Rail</th>\n",
              "      <th>Sea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UrxgnsxUeNzYCc3JE7HUUq</td>\n",
              "      <td>-0.659682</td>\n",
              "      <td>A</td>\n",
              "      <td>0.042737</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.771546</td>\n",
              "      <td>0.238178</td>\n",
              "      <td>-0.095585</td>\n",
              "      <td>-0.440100</td>\n",
              "      <td>0.228457</td>\n",
              "      <td>0.076958</td>\n",
              "      <td>0.761144</td>\n",
              "      <td>0.724196</td>\n",
              "      <td>0.797852</td>\n",
              "      <td>-0.095585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JtTx82Q6URXeE5gjPHvhXg</td>\n",
              "      <td>-0.664812</td>\n",
              "      <td>E</td>\n",
              "      <td>-0.723658</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.635297</td>\n",
              "      <td>0.459958</td>\n",
              "      <td>0.610066</td>\n",
              "      <td>-0.444787</td>\n",
              "      <td>0.236975</td>\n",
              "      <td>-0.048146</td>\n",
              "      <td>-0.807050</td>\n",
              "      <td>-0.497392</td>\n",
              "      <td>-0.226956</td>\n",
              "      <td>0.610066</td>\n",
              "      <td>-0.048146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PpnUphc4CcpchL9Aw6oKVT</td>\n",
              "      <td>-0.484102</td>\n",
              "      <td>C</td>\n",
              "      <td>0.400635</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.093454</td>\n",
              "      <td>0.264699</td>\n",
              "      <td>0.294330</td>\n",
              "      <td>-0.474819</td>\n",
              "      <td>-0.360806</td>\n",
              "      <td>0.320143</td>\n",
              "      <td>-0.535535</td>\n",
              "      <td>0.304031</td>\n",
              "      <td>-0.444529</td>\n",
              "      <td>0.294330</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>kdudBNL8pKRZhRon5tpKGP</td>\n",
              "      <td>0.162117</td>\n",
              "      <td>B</td>\n",
              "      <td>-0.705877</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.479565</td>\n",
              "      <td>-0.111289</td>\n",
              "      <td>-0.109478</td>\n",
              "      <td>0.245272</td>\n",
              "      <td>0.181443</td>\n",
              "      <td>0.620818</td>\n",
              "      <td>-0.948521</td>\n",
              "      <td>0.586308</td>\n",
              "      <td>-0.111289</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>YUz8cVMQsQiSG5as6fcX3d</td>\n",
              "      <td>-0.269855</td>\n",
              "      <td>D</td>\n",
              "      <td>-0.056087</td>\n",
              "      <td>0</td>\n",
              "      <td>0.786691</td>\n",
              "      <td>-0.151074</td>\n",
              "      <td>-0.109013</td>\n",
              "      <td>-0.697314</td>\n",
              "      <td>-0.581735</td>\n",
              "      <td>-0.137185</td>\n",
              "      <td>0.177713</td>\n",
              "      <td>-0.590824</td>\n",
              "      <td>0.946205</td>\n",
              "      <td>-0.109013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfb7ad58-48a7-4f37-8b16-9472321e6974')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dfb7ad58-48a7-4f37-8b16-9472321e6974 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dfb7ad58-48a7-4f37-8b16-9472321e6974');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               Product_Id  Net_Weight Size     Value  Storage  Packaging_Cost  \\\n",
              "0  UrxgnsxUeNzYCc3JE7HUUq   -0.659682    A  0.042737        0       -0.771546   \n",
              "1  JtTx82Q6URXeE5gjPHvhXg   -0.664812    E -0.723658        0       -0.635297   \n",
              "2  PpnUphc4CcpchL9Aw6oKVT   -0.484102    C  0.400635        0       -0.093454   \n",
              "3  kdudBNL8pKRZhRon5tpKGP    0.162117    B -0.705877        0        0.000646   \n",
              "4  YUz8cVMQsQiSG5as6fcX3d   -0.269855    D -0.056087        0        0.786691   \n",
              "\n",
              "   Expiry_Period    Length    Height     Width    Volume  Perishable_Index  \\\n",
              "0       0.238178 -0.095585 -0.440100  0.228457  0.076958          0.761144   \n",
              "1       0.459958  0.610066 -0.444787  0.236975 -0.048146         -0.807050   \n",
              "2       0.264699  0.294330 -0.474819 -0.360806  0.320143         -0.535535   \n",
              "3       0.479565 -0.111289 -0.109478  0.245272  0.181443          0.620818   \n",
              "4      -0.151074 -0.109013 -0.697314 -0.581735 -0.137185          0.177713   \n",
              "\n",
              "   Flammability_Index      F145     F7987      F992  Air  Road  Rail  Sea  \n",
              "0            0.724196  0.797852 -0.095585       NaN    0     0     0    1  \n",
              "1           -0.497392 -0.226956  0.610066 -0.048146    0     0     0    1  \n",
              "2            0.304031 -0.444529  0.294330       NaN    0     1     0    0  \n",
              "3           -0.948521  0.586308 -0.111289       NaN    0     1     0    1  \n",
              "4           -0.590824  0.946205 -0.109013       NaN    0     1     0    0  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sample of data\n",
        "query = \"\"\"SELECT * FROM `empirical-realm-374307.transport_dataset.product_transport` LIMIT 10\"\"\"\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxoUMzZyFWB8"
      },
      "source": [
        "The below SQL query is selecting the count of all rows in the product_transport table from the transport_dataset dataset in Google BigQuery. The COUNT() function is used to count the number of rows in the table. The * specifies that we want to count all rows in the table. The AS NUM part of the query is used to alias the result of the COUNT() function as NUM.\n",
        "\n",
        "Here are explanations of the SQL functions used in this query:\n",
        "\n",
        "* COUNT(): a function used to count the number of rows returned by a query. The * inside the parentheses specifies that we want to count all rows in the table.\n",
        "\n",
        "* AS: a keyword used to alias a column or an expression in a query result. In this case, we are aliasing the result of the COUNT(*) function as NUM. This makes the output easier to read and understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "nprUMQ5Ciqw1",
        "outputId": "38fa2e1d-a1a4-47ba-8f10-31a0a6a4de89"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-24f2052e-3dfc-4414-a409-0f5cf9bb4596\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NUM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24f2052e-3dfc-4414-a409-0f5cf9bb4596')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24f2052e-3dfc-4414-a409-0f5cf9bb4596 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24f2052e-3dfc-4414-a409-0f5cf9bb4596');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    NUM\n",
              "0  2000"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count number of rows\n",
        "query = \"\"\"SELECT COUNT(*) AS NUM FROM `empirical-realm-374307.transport_dataset.product_transport`\"\"\"\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMeFp98gF-A5"
      },
      "source": [
        "This SQL query is used to count the number of distinct products in the product_transport table in the transport_dataset dataset. The query starts with the SELECT keyword to specify the information that we want to retrieve. In this case, we are counting the number of distinct products, so we use the COUNT(DISTINCT Product_Id) function. The AS Num_Products clause is used to rename the resulting column as \"Num_Products\". Finally, we specify the name of the table we want to query with the FROM keyword and the dataset name.\n",
        "\n",
        "The new SQL functions used in this query are:\n",
        "\n",
        "\n",
        "* DISTINCT: This keyword is used to retrieve only the unique values of a specific column. In this query, we use it with Product_Id to count the number of distinct products.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "8HxYB7hsi1n2",
        "outputId": "b298c721-2ce1-437d-901c-c42aac85c2b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c3b4063-bb9c-43b4-a3a6-32ab43f3e7e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Num_Products</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c3b4063-bb9c-43b4-a3a6-32ab43f3e7e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c3b4063-bb9c-43b4-a3a6-32ab43f3e7e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c3b4063-bb9c-43b4-a3a6-32ab43f3e7e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Num_Products\n",
              "0          2000"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count distinct products\n",
        "query = \"\"\"SELECT COUNT(DISTINCT Product_Id) AS Num_Products FROM `empirical-realm-374307.transport_dataset.product_transport`\"\"\"\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93TAt2nVw5lm"
      },
      "source": [
        "So we have as many products as rows!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQGvYpllG32j"
      },
      "source": [
        "In the following code, a query is constructed to obtain statistics on the numerical features of the product_transport dataset in BigQuery. The columns considered as numerical features are Net_Weight, Value, Packaging_Cost, Expiry_Period, Length, Height, Width, Volume, Perishable_Index, Flammability_Index, F145, F7987, and F992.\n",
        "\n",
        "To obtain the statistics for each numerical feature, a subquery is constructed for each column. Each subquery selects the name of the column as \"Name\" and the corresponding column values as \"Value\". The subqueries are then combined using the UNION ALL clause to create a single table with columns \"Name\" and \"Value\".\n",
        "\n",
        "The resulting table is then used to compute the minimum, maximum, average, and number of missing values for each numerical feature. This is done using the MIN(), MAX(), SUM(), COUNT(), and CASE WHEN...THEN...END functions in SQL. \n",
        "\n",
        "* SELECT: This function is used to choose the columns to include in the result set.\n",
        "\n",
        "* MIN: This function is used to find the minimum value in a column.\n",
        "\n",
        "* MAX: This function is used to find the maximum value in a column.\n",
        "\n",
        "* AVG: This function is used to find the average value in a column.\n",
        "\n",
        "* SUM: This function is used to find the sum of values in a column.\n",
        "\n",
        "* COUNT: This function is used to count the number of non-null values in a column.\n",
        "\n",
        "* CASE: This function is used to conditionally select values in a column. It takes an expression, evaluates it, and returns a value based on the result. In this code, it is used to count the number of missing values in a column. The CASE keyword is followed by one or more WHEN clauses, each of which specifies a condition to test. If the condition is true, the corresponding THEN clause is executed and its result is returned. If none of the conditions are true, the ELSE clause is executed and its result is returned.\n",
        "\n",
        "* The WHEN and ELSE clauses can also contain more complex expressions or even subqueries. In addition, you can use the CASE statement as a column expression in a SELECT statement to create new calculated columns based on the values of existing columns.\n",
        "\n",
        "* One common use of the CASE statement is to handle NULL values. You can use the IS NULL or IS NOT NULL operators in a WHEN clause to test for NULL values and handle them accordingly. \n",
        "\n",
        "* The UNION ALL clause is used to combine the results of multiple subqueries with the same structure. In this case, since all subqueries have the same number of columns and column names, UNION ALL is used to stack the results of the subqueries into a single table. The resulting table can then be used to compute statistics across all the numerical features using SQL functions.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "IK245BK3v0pm",
        "outputId": "d717423c-eed8-4f98-d797-298cb70c27b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc528efb-33fd-462a-abfe-83b2d6b0d9a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Min</th>\n",
              "      <th>Avg</th>\n",
              "      <th>Max</th>\n",
              "      <th>NumMissing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F992</td>\n",
              "      <td>-0.959772</td>\n",
              "      <td>0.034505</td>\n",
              "      <td>0.927373</td>\n",
              "      <td>746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F7987</td>\n",
              "      <td>-297.000000</td>\n",
              "      <td>1.417082</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F145</td>\n",
              "      <td>-0.998497</td>\n",
              "      <td>-0.000811</td>\n",
              "      <td>0.999786</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Flammability_Index</td>\n",
              "      <td>-0.999492</td>\n",
              "      <td>-0.012068</td>\n",
              "      <td>0.999227</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Perishable_Index</td>\n",
              "      <td>-0.997374</td>\n",
              "      <td>0.004832</td>\n",
              "      <td>0.999453</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Volume</td>\n",
              "      <td>-0.959772</td>\n",
              "      <td>0.028498</td>\n",
              "      <td>0.927373</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Width</td>\n",
              "      <td>-0.928478</td>\n",
              "      <td>0.112865</td>\n",
              "      <td>0.876141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Height</td>\n",
              "      <td>-0.989023</td>\n",
              "      <td>-0.199589</td>\n",
              "      <td>0.810998</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Length</td>\n",
              "      <td>-0.854964</td>\n",
              "      <td>-0.035019</td>\n",
              "      <td>0.888716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Expiry_Period</td>\n",
              "      <td>-0.640952</td>\n",
              "      <td>0.196590</td>\n",
              "      <td>0.881765</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Packaging_Cost</td>\n",
              "      <td>-0.956013</td>\n",
              "      <td>-0.130105</td>\n",
              "      <td>0.838401</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Value</td>\n",
              "      <td>-0.895737</td>\n",
              "      <td>-0.090483</td>\n",
              "      <td>0.958518</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Net_Weight</td>\n",
              "      <td>-0.988196</td>\n",
              "      <td>-0.057748</td>\n",
              "      <td>0.913435</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc528efb-33fd-462a-abfe-83b2d6b0d9a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc528efb-33fd-462a-abfe-83b2d6b0d9a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc528efb-33fd-462a-abfe-83b2d6b0d9a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  Name         Min       Avg         Max  NumMissing\n",
              "0                 F992   -0.959772  0.034505    0.927373         746\n",
              "1                F7987 -297.000000  1.417082  299.000000           0\n",
              "2                 F145   -0.998497 -0.000811    0.999786           0\n",
              "3   Flammability_Index   -0.999492 -0.012068    0.999227           0\n",
              "4     Perishable_Index   -0.997374  0.004832    0.999453          47\n",
              "5               Volume   -0.959772  0.028498    0.927373           0\n",
              "6                Width   -0.928478  0.112865    0.876141           0\n",
              "7               Height   -0.989023 -0.199589    0.810998           0\n",
              "8               Length   -0.854964 -0.035019    0.888716           0\n",
              "9        Expiry_Period   -0.640952  0.196590    0.881765         100\n",
              "10      Packaging_Cost   -0.956013 -0.130105    0.838401           0\n",
              "11               Value   -0.895737 -0.090483    0.958518           0\n",
              "12          Net_Weight   -0.988196 -0.057748    0.913435           0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# numerical features\n",
        "\n",
        "columns = ['Net_Weight', 'Value', 'Packaging_Cost', 'Expiry_Period', 'Length', 'Height', 'Width', 'Volume', 'Perishable_Index', 'Flammability_Index', 'F145', 'F7987', 'F992']\n",
        "selects = [f\"\\n\\t(SELECT '{col}' AS Name, {col} AS Value FROM `empirical-realm-374307.transport_dataset.product_transport`)\\n\" for col in columns]\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT Name, MIN(Value) AS Min, SUM(Value) / COUNT(Value) AS Avg, MAX(Value) AS Max, SUM(CASE WHEN Value IS NULL THEN 1 ELSE 0 END) AS NumMissing\n",
        "FROM ({'UNION ALL'.join(selects)})\n",
        "GROUP BY Name\n",
        "\"\"\"\n",
        "\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head(len(columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XytyO8lUQpJr"
      },
      "source": [
        "The SQL query `SELECT Size, COUNT(*) AS Num FROM empirical-realm-374307.transport_dataset.product_transport GROUP BY 1 ORDER BY 2 DESC` is used to retrieve the count of each unique value in the Size column of the product_transport table. The GROUP BY 1 clause groups the result set by the first column in the select statement, which is Size. The COUNT(*) function counts the number of times each Size value appears in the table. The ORDER BY 2 DESC clause sorts the result set in descending order based on the count of each unique Size value.\n",
        "\n",
        "* GROUP BY: This is used to group rows with the same value in a particular column. In the query, it is used to group the rows by the Size column.\n",
        "\n",
        "* ORDER BY: This is used to sort the result set in ascending or descending order based on one or more columns. In the query, it is used to sort the result set by the count of each unique value in the Size column in descending order.\n",
        "\n",
        "* 1: In the GROUP BY clause, 1 is used as a shorthand to refer to the first column in the SELECT statement, which is the Size column in this case. This is a common shorthand used in SQL to avoid typing out the full column name again in the GROUP BY clause."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DhS-khRs1tvv",
        "outputId": "fb21ae01-8316-43d9-92d1-ebc62c8c1e82"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a60ec9bd-2788-450c-b864-ddae82e27690\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>Num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E</td>\n",
              "      <td>661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D</td>\n",
              "      <td>575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C</td>\n",
              "      <td>369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a60ec9bd-2788-450c-b864-ddae82e27690')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a60ec9bd-2788-450c-b864-ddae82e27690 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a60ec9bd-2788-450c-b864-ddae82e27690');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Size  Num\n",
              "0    E  661\n",
              "1    D  575\n",
              "2    C  369\n",
              "3    B  268\n",
              "4    A  127"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"\"\"SELECT Size, COUNT(*) AS Num FROM `empirical-realm-374307.transport_dataset.product_transport` GROUP BY 1 ORDER BY 2 DESC\"\"\"\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Z9hXoWiy_nw_",
        "outputId": "a2ecbe09-f210-4b9a-b7b3-ae689ef54124"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d04f6acb-7f5b-46f5-8c45-01d1e9880507\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Storage</th>\n",
              "      <th>Num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d04f6acb-7f5b-46f5-8c45-01d1e9880507')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d04f6acb-7f5b-46f5-8c45-01d1e9880507 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d04f6acb-7f5b-46f5-8c45-01d1e9880507');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Storage   Num\n",
              "0        0  1071\n",
              "1        1   929"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"\"\"SELECT Storage, COUNT(*) AS Num FROM `empirical-realm-374307.transport_dataset.product_transport` GROUP BY 1 ORDER BY 2 DESC\"\"\"\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "V8dENxrU_4zW",
        "outputId": "dde18774-f227-4bb7-89e4-95a76a673b91"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-283bcaa5-d1af-421f-87dc-aaf041c74566\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Air</th>\n",
              "      <th>Road</th>\n",
              "      <th>Rail</th>\n",
              "      <th>Sea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.211</td>\n",
              "      <td>0.586</td>\n",
              "      <td>0.4215</td>\n",
              "      <td>0.271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-283bcaa5-d1af-421f-87dc-aaf041c74566')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-283bcaa5-d1af-421f-87dc-aaf041c74566 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-283bcaa5-d1af-421f-87dc-aaf041c74566');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Air   Road    Rail    Sea\n",
              "0  0.211  0.586  0.4215  0.271"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"\"\"\n",
        "SELECT \n",
        "    AVG(Air) AS Air, \n",
        "    AVG(Road) AS Road, \n",
        "    AVG(Rail) AS Rail, \n",
        "    AVG(Sea) AS Sea\n",
        "FROM `empirical-realm-374307.transport_dataset.product_transport`\"\"\"\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcYHPBcceTRB"
      },
      "source": [
        "## **Get data from BigQuery & Encode categorical variables**\n",
        "\n",
        "This code is creating a SQL query to extract data from the product_transport table in BigQuery. The query is selecting certain numerical features, such as weight and value, as well as some categorical feature Size.\n",
        "\n",
        "In addition to extracting the original Size feature, this query is also performing one-hot encoding on the Size feature, which is essentially converting the categorical variable into a binary vector. For instance, Size_A column will have a value of 1 if the original Size value was A, and 0 otherwise. Similarly, other columns Size_B, Size_C and Size_D will have values of 1 if the original Size value was B, C or D, respectively.\n",
        "\n",
        "\n",
        "### **One Hot Encoding**\n",
        "\n",
        "One-hot encoding is a process of representing categorical data in a numerical format that machine learning models can understand. In machine learning, it's common to have categorical data, such as gender, color, or size, that cannot be directly processed by algorithms. One-hot encoding solves this problem by converting categorical data into numerical data, which algorithms can process.\n",
        "\n",
        "One-hot encoding is achieved by creating a binary column for each possible category in a categorical variable. Each binary column represents a category and is set to 1 if the observation belongs to that category or 0 otherwise. For example, in the given code, the Size categorical variable is one-hot encoded by creating four binary columns (Size_A, Size_B, Size_C, and Size_D) that represent the four possible categories in the Size variable. If an observation belongs to a particular category, the binary column representing that category is set to 1, and all other columns are set to 0.\n",
        "\n",
        "One-hot encoding is an essential preprocessing step in many machine learning projects, as it allows categorical data to be used as input to machine learning algorithms, which typically expect numerical inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "dqy9FgE1GfrA",
        "outputId": "84c6df19-83c8-4e09-afde-b0d61b90220f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-df799635-f556-4a6f-a6f4-9ab6cca159b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Net_Weight</th>\n",
              "      <th>Value</th>\n",
              "      <th>Packaging_Cost</th>\n",
              "      <th>Expiry_Period</th>\n",
              "      <th>Length</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Perishable_Index</th>\n",
              "      <th>Flammability_Index</th>\n",
              "      <th>...</th>\n",
              "      <th>F7987</th>\n",
              "      <th>F992</th>\n",
              "      <th>Size_A</th>\n",
              "      <th>Size_B</th>\n",
              "      <th>Size_C</th>\n",
              "      <th>Size_D</th>\n",
              "      <th>Air</th>\n",
              "      <th>Road</th>\n",
              "      <th>Rail</th>\n",
              "      <th>Sea</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.659682</td>\n",
              "      <td>0.042737</td>\n",
              "      <td>-0.771546</td>\n",
              "      <td>0.238178</td>\n",
              "      <td>-0.095585</td>\n",
              "      <td>-0.440100</td>\n",
              "      <td>0.228457</td>\n",
              "      <td>0.076958</td>\n",
              "      <td>0.761144</td>\n",
              "      <td>0.724196</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.095585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.664812</td>\n",
              "      <td>-0.723658</td>\n",
              "      <td>-0.635297</td>\n",
              "      <td>0.459958</td>\n",
              "      <td>0.610066</td>\n",
              "      <td>-0.444787</td>\n",
              "      <td>0.236975</td>\n",
              "      <td>-0.048146</td>\n",
              "      <td>-0.807050</td>\n",
              "      <td>-0.497392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.610066</td>\n",
              "      <td>-0.048146</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.484102</td>\n",
              "      <td>0.400635</td>\n",
              "      <td>-0.093454</td>\n",
              "      <td>0.264699</td>\n",
              "      <td>0.294330</td>\n",
              "      <td>-0.474819</td>\n",
              "      <td>-0.360806</td>\n",
              "      <td>0.320143</td>\n",
              "      <td>-0.535535</td>\n",
              "      <td>0.304031</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294330</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.162117</td>\n",
              "      <td>-0.705877</td>\n",
              "      <td>0.000646</td>\n",
              "      <td>0.479565</td>\n",
              "      <td>-0.111289</td>\n",
              "      <td>-0.109478</td>\n",
              "      <td>0.245272</td>\n",
              "      <td>0.181443</td>\n",
              "      <td>0.620818</td>\n",
              "      <td>-0.948521</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.111289</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.269855</td>\n",
              "      <td>-0.056087</td>\n",
              "      <td>0.786691</td>\n",
              "      <td>-0.151074</td>\n",
              "      <td>-0.109013</td>\n",
              "      <td>-0.697314</td>\n",
              "      <td>-0.581735</td>\n",
              "      <td>-0.137185</td>\n",
              "      <td>0.177713</td>\n",
              "      <td>-0.590824</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.109013</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df799635-f556-4a6f-a6f4-9ab6cca159b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df799635-f556-4a6f-a6f4-9ab6cca159b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df799635-f556-4a6f-a6f4-9ab6cca159b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Net_Weight     Value  Packaging_Cost  Expiry_Period    Length    Height  \\\n",
              "0   -0.659682  0.042737       -0.771546       0.238178 -0.095585 -0.440100   \n",
              "1   -0.664812 -0.723658       -0.635297       0.459958  0.610066 -0.444787   \n",
              "2   -0.484102  0.400635       -0.093454       0.264699  0.294330 -0.474819   \n",
              "3    0.162117 -0.705877        0.000646       0.479565 -0.111289 -0.109478   \n",
              "4   -0.269855 -0.056087        0.786691      -0.151074 -0.109013 -0.697314   \n",
              "\n",
              "      Width    Volume  Perishable_Index  Flammability_Index  ...     F7987  \\\n",
              "0  0.228457  0.076958          0.761144            0.724196  ... -0.095585   \n",
              "1  0.236975 -0.048146         -0.807050           -0.497392  ...  0.610066   \n",
              "2 -0.360806  0.320143         -0.535535            0.304031  ...  0.294330   \n",
              "3  0.245272  0.181443          0.620818           -0.948521  ... -0.111289   \n",
              "4 -0.581735 -0.137185          0.177713           -0.590824  ... -0.109013   \n",
              "\n",
              "       F992  Size_A  Size_B  Size_C  Size_D  Air  Road  Rail  Sea  \n",
              "0       NaN       1       0       0       0    0     0     0    1  \n",
              "1 -0.048146       0       0       0       0    0     0     0    1  \n",
              "2       NaN       0       0       1       0    0     1     0    0  \n",
              "3       NaN       0       1       0       0    0     1     0    1  \n",
              "4       NaN       0       0       0       1    0     1     0    0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_features = ['Net_Weight', 'Value', 'Packaging_Cost', 'Expiry_Period', 'Length', 'Height', 'Width', 'Volume', 'Perishable_Index', 'Flammability_Index', 'F145', 'F7987', 'F992']\n",
        "labels = ['Air', 'Road', 'Rail', 'Sea']\n",
        "preserve(\"715840\")\n",
        "query = f\"\"\"\n",
        "SELECT \n",
        "    {','.join(num_features)},\n",
        "    CASE WHEN Size = 'A' THEN 1 ELSE 0 END Size_A,\n",
        "    CASE WHEN Size = 'B' THEN 1 ELSE 0 END Size_B,\n",
        "    CASE WHEN Size = 'C' THEN 1 ELSE 0 END Size_C,\n",
        "    CASE WHEN Size = 'D' THEN 1 ELSE 0 END Size_D,\n",
        "    {','.join(labels)}\n",
        "FROM `empirical-realm-374307.transport_dataset.product_transport`\"\"\"\n",
        "s = gbq.read_gbq(query, project_id='empirical-realm-374307')\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiikPMZaeiYt"
      },
      "source": [
        "## **Modeling**\n",
        "\n",
        "### **Supervised Machine Learning**\n",
        "\n",
        "Supervised learning is a type of machine learning where the algorithm learns from labeled data. In other words, the data used to train the algorithm includes input variables and corresponding output variables. The algorithm learns to predict the output variable based on the input variables. Supervised learning can be further divided into two categories: regression and classification.\n",
        "\n",
        "* **Regression** is a type of supervised learning where the algorithm learns to predict a continuous output variable. In other words, the output variable is a numerical value. Examples of regression problems include predicting housing prices, stock prices, or the amount of rainfall in a particular area.\n",
        "\n",
        "* **Classification**, on the other hand, is a type of supervised learning where the algorithm learns to predict a discrete output variable. In other words, the output variable is a category or label. Examples of classification problems include predicting whether an email is spam or not, whether a tumor is malignant or benign, or whether a customer is likely to churn or not.\n",
        "\n",
        "## **Decision Trees**\n",
        "\n",
        "**Decision Trees in Classification**\n",
        "\n",
        "Decision trees are a type of supervised learning algorithm that can be used for classification as well as regression problems. They are widely used in machine learning because they are easy to understand and interpret, and can handle both categorical and numerical data. The idea behind decision trees is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n",
        "\n",
        "The decision tree starts with a single node, called the root node, which represents the entire dataset. The root node is then split into several child nodes based on the value of a chosen feature. The process of selecting the best feature and splitting the nodes is repeated recursively for each child node until a stopping criterion is reached. This results in a tree-like structure that represents the decision rules learned from the data.\n",
        "\n",
        "Each node in the decision tree represents a decision or a test of a feature value, and each branch represents the possible outcomes of that decision. The leaves of the tree represent the final decision or the class label assigned to the input data.\n",
        "\n",
        "**Splitting Criteria**\n",
        "\n",
        "To build a decision tree, we need a measure that determines how to split the data at each node. The splitting criterion is chosen based on the type of data and the nature of the problem. The most common splitting criteria are:\n",
        "\n",
        "* Gini index: measures the impurity of a set of labels. It calculates the probability of misclassifying a randomly chosen element from the set, and is used to minimize misclassification errors.\n",
        "* Information gain: measures the reduction in entropy (uncertainty) after a split. It is used to maximize the information gain in each split.\n",
        "* Chi-square: measures the difference between observed and expected frequencies of the classes. It is used to minimize the deviation between the observed and expected class distribution.\n",
        "\n",
        "**Overfitting in Decision Trees**\n",
        "\n",
        "One of the main challenges in building decision trees is overfitting. Overfitting occurs when the tree is too complex and fits the training data too well, resulting in poor performance on new and unseen data. This can be addressed by pruning the tree or limiting its depth, or by using ensemble methods such as bagging and boosting.\n",
        "\n",
        "**Ensemble Methods**\n",
        "\n",
        "Ensemble methods are techniques that combine multiple models to improve performance and reduce overfitting. The two most common ensemble methods used with decision trees are:\n",
        "\n",
        "* Bagging (Bootstrap Aggregating): involves training multiple decision trees on different subsets of the training data and then combining their predictions by averaging or voting. This reduces the variance and improves the stability of the model.\n",
        "* Boosting: involves training multiple decision trees sequentially, where each subsequent tree focuses on the misclassified examples of the previous tree. This reduces the bias and improves the accuracy of the model.\n",
        "\n",
        "Deecision trees are powerful tools for classification problems that provide a clear and interpretable representation of the decision rules learned from the data. The choice of splitting criterion, stopping criterion, and ensemble method can have a significant impact on the performance and generalization of the model.\n",
        "\n",
        "### **Bagging**\n",
        "\n",
        "\n",
        "\n",
        "Bagging is an ensemble learning technique that aims to decrease the variance of a single estimator by combining the predictions from multiple learners. The basic idea behind bagging is to generate multiple versions of the training dataset through random sampling with replacement, and then train a separate classifier for each sampled dataset. The predictions from these individual classifiers are then combined using averaging or voting to obtain a final prediction.\n",
        "\n",
        "**Algorithm:**\n",
        "\n",
        "Suppose we have a training set D of size n, and we want to train a classifier using bagging. Here are the steps involved:\n",
        "\n",
        "* Create k different bootstrap samples from D, each of size n.\n",
        "* Train a classifier on each bootstrap sample.\n",
        "* When making predictions on a new data point, take the average or majority vote of the predictions from each of the k classifiers.\n",
        "\n",
        "\n",
        "**Mathematical Explanation:**\n",
        "\n",
        "Suppose we have a binary classification problem with classes -1 and 1. Let's also assume that we have a training set D of size n, and we want to train a decision tree classifier using bagging.\n",
        "\n",
        "**Bootstrap Sample**: For each of the k classifiers, we create a bootstrap sample of size n by sampling with replacement from D. This means that each bootstrap sample may contain duplicates of some instances and may also miss some instances from the original dataset. Let's denote the i-th bootstrap sample as D_i.\n",
        "\n",
        "**Train a Classifier**: We train a decision tree classifier T_i on each bootstrap sample D_i. This gives us k classifiers T_1, T_2, ..., T_k.\n",
        "\n",
        "**Combine Predictions**: To make a prediction on a new data point x, we take the majority vote of the predictions from each of the k classifiers. \n",
        "\n",
        "The idea behind bagging is that the variance of the prediction error decreases as k increases. This is because each classifier has a chance to explore a different part of the feature space due to the random sampling with replacement, and the final prediction is a combination of these diverse classifiers.\n",
        "\n",
        "### **Random Forest**\n",
        "\n",
        "\n",
        "\n",
        "Random Forest is an ensemble learning algorithm that builds a large number of decision trees and combines them to make a final prediction. It is a type of bagging method, where multiple decision trees are trained on random subsets of the training data and features. The algorithm then averages the predictions of these individual trees to produce a final prediction. Random Forest is particularly useful for handling high-dimensional data and for avoiding overfitting.\n",
        "\n",
        "**Algorithm of Random Forest**\n",
        "\n",
        "The algorithm of Random Forest can be summarized in the following steps:\n",
        "\n",
        "* Start by randomly selecting a subset of the training data, with replacement. This subset is called the bootstrap sample.\n",
        "\n",
        "* Next, randomly select a subset of features from the full feature set.\n",
        "\n",
        "* Build a decision tree using the bootstrap sample and the selected subset of features. At each node of the tree, select the best feature and split the data based on the selected feature.\n",
        "\n",
        "* Repeat steps 1-3 to build multiple trees.\n",
        "\n",
        "* Finally, combine the predictions of all trees to make a final prediction. For classification, this is usually done by taking a majority vote of the predicted classes. For regression, this is usually done by taking the average of the predicted values.\n",
        "\n",
        "\n",
        "**Mathematics Behind Random Forest**\n",
        "\n",
        "The mathematics behind Random Forest involves the use of decision trees and the bootstrap sampling technique. Decision trees are constructed using a recursive binary partitioning algorithm that splits the data based on the values of the selected features. At each node, the algorithm chooses the feature and the split point that maximizes the information gain. Information gain measures the reduction in entropy or impurity of the target variable after the split. The goal is to minimize the impurity of the subsets after each split.\n",
        "\n",
        "Bootstrap sampling is a statistical technique that involves randomly sampling the data with replacement to create multiple subsets. These subsets are used to train individual decision trees. By using bootstrap samples, the algorithm can generate multiple versions of the same dataset with slightly different distributions. This introduces randomness into the training process, which helps to reduce overfitting.\n",
        "\n",
        "\n",
        "\n",
        "**Difference between Bagging and Random Forest**\n",
        "\n",
        "Bagging and Random Forest are both ensemble learning algorithms that involve training multiple models on random subsets of the data. The main difference between the two is the way the individual models are trained.\n",
        "\n",
        "Bagging involves training multiple models using the bootstrap sampling technique, but each model uses the same set of features. This can lead to correlated predictions, which reduces the variance but not necessarily the bias of the model.\n",
        "\n",
        "Random Forest, on the other hand, involves training multiple models using the bootstrap sampling technique, but each model uses a randomly selected subset of features. This introduces additional randomness into the model and helps to reduce the correlation between individual predictions. Random Forest can achieve better performance than Bagging, especially when dealing with high-dimensional data or noisy features. In simpler terms it uses subsets of observations as well as features.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### **Boosting**\n",
        "\n",
        "Boosting is a machine learning algorithm that works by combining several weak models (also known as base learners) into a strong model. The goal of boosting is to reduce the bias and variance of the base learners by iteratively adding new models to the ensemble that focus on correcting the errors made by the previous models. In other words, the boosting algorithm tries to learn from the mistakes of the previous models and improve the overall accuracy of the ensemble.\n",
        "\n",
        "Boosting works by assigning higher weights to the data points that the previous models misclassified, and lower weights to the ones that were classified correctly. This ensures that the new model focuses more on the difficult data points that the previous models struggled with, and less on the ones that were already well-classified. As a result, the new model is more specialized and can improve the accuracy of the ensemble.\n",
        "\n",
        "There are several types of boosting algorithms, including AdaBoost (Adaptive Boosting), Gradient Boosting, and XGBoost (Extreme Gradient Boosting). Each of these algorithms has its own approach to assigning weights to the data points and building the new models, but they all share the fundamental idea of iteratively improving the accuracy of the ensemble by combining weak models into a strong one. Boosting is a powerful algorithm that has been shown to achieve state-of-the-art results in many machine learning tasks, such as image classification, natural language processing, and recommender systems.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Difference between Bagging and Boosting**\n",
        "\n",
        "\n",
        "It's important to remember that boosting is a generic method, not a specific model, in order to comprehend it. Boosting involves specifying a weak model, such as regression or decision trees, and then improving it. In Ensemble Learning, the primary difference between Bagging and Boosting is that in bagging, weak learners are trained in simultaneously, but in boosting, they are trained sequentially. This means that each new model iteration increases the weights of the prior model's misclassified data. This redistribution of weights aids the algorithm in determining which parameters it should focus on in order to increase its performance.\n",
        "\n",
        "Both the Ensemble techniques are used in a different way as well.  Bagging methods, for example, are often used on poor learners who have large variance and low bias such as decision trees because they tend to overfit, whereas boosting methods are employed when there is low variance and high bias. While bagging can help prevent overfitting, boosting methods are more vulnerable to it because of a simple fact they continue to build on weak learners and continue to minimise error. This can lead to overfitting on the training data but specifying a decent number of models to be generated or hyperparameter tuning,  regularization can help in this case, if overfitting encountered.\n",
        "\n",
        "\n",
        "### **Gradient Boosting**\n",
        "\n",
        "The primary idea behind this technique is to develop models in a sequential manner, with each model attempting to reduce the mistakes of the previous model.The additive model, loss function, and a weak learner are the three fundamental components of Gradient Boosting.\n",
        "\n",
        "The method provides a direct interpretation of boosting in terms of numerical optimization of the loss function using Gradient Descent. We employ Gradient Boosting Regressor when the target column is continuous, and Gradient Boosting Classifier when the task is a classification problem. The \"Loss function\" is the only difference between the two. The goal is to use gradient descent to reduce this loss function by adding weak learners. Because it is based on loss functions, for regression problems, Mean squared error (MSE) will be used, and  for classification problems, log-likelihood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trr4k5krVZks"
      },
      "source": [
        "### **LightGBM Model**\n",
        "\n",
        "LightGBM is designed to be a \"light\" gradient boosting framework with several features that make it more efficient than other popular frameworks like XGBoost or CatBoost. One of the reasons why it's considered \"light\" is that it uses a vertical tree growth method that is more efficient than the horizontal growth method used by other frameworks.\n",
        "\n",
        "In traditional tree-based models such as decision trees and random forests, trees are grown level-wise, which means the algorithm grows the same level of nodes for each feature before moving to the next level. For example, if a tree has a depth of 3 and is being built on two features, the algorithm would first split the root node by selecting the best feature and threshold that maximizes the information gain. Then, it would split each of the resulting child nodes, and so on until the tree reaches the specified depth.\n",
        "\n",
        "In contrast, LightGBM grows trees leaf-wise, which means it first selects the leaf with the largest delta loss to grow. This method can reduce the loss more than a level-wise strategy when expanding the same leaf.\n",
        "\n",
        "For example, let's consider a dataset with one feature and 1000 samples. In a level-wise approach, the algorithm would split the first node into two nodes each with 500 samples, then split each of those nodes into two nodes each with 250 samples, and so on until the tree is fully grown. In contrast, in a leaf-wise approach, the algorithm would select the leaf with the largest delta loss, which could be any leaf at any depth, and grow that leaf first. This approach may result in fewer nodes being grown overall and can lead to faster training times and better accuracy.\n",
        "\n",
        "Light GBM is prefixed as ‘Light’ because of its high speed. Light GBM can handle the large size of data and takes lower memory to run.\n",
        "\n",
        "**Control Parameters**\n",
        "\n",
        "\n",
        "* max_depth: It describes the maximum depth of a tree. To manage overfitting of the model, utilize this parameter. \n",
        "\n",
        "\n",
        "* min_data_in_leaf: It is the minimum number of the records a leaf has. The default value is 20.\n",
        "\n",
        "\n",
        "* feature_fraction: % of parameters randomly selected in each iteration for building trees.\n",
        "\n",
        "\n",
        "* bagging_fraction: It is typically used to speed up training and prevent overfitting. It sets the percentage of data to be used for each iteration.\n",
        "\n",
        "\n",
        "* early_stopping_round: If one validation data measure does not improve in the last early stopping round rounds, the model will cease training. This will cut down on unnecessary iterations.\n",
        "\n",
        "\n",
        "* lambda: lambda specifies the level of regularization. Typical value ranges from 0 to 1.\n",
        "\n",
        "\n",
        "* min gain to split: This value will specify the required minimum gain to split. It can be used to control the number of useful splits in a tree.\n",
        "\n",
        "\n",
        "* max_cat_group: Finding the split point on it is easily over-fitting when the number of categories is huge. In order to combine them, LightGBM creates groups named \"max cat group\" and determines the split points on the group boundaries (default: 64).\n",
        "\n",
        "**Core Parameters**\n",
        "\n",
        "* Task: It specifies the task you want to perform on data, train or predict.\n",
        "\n",
        "\n",
        "* application: This is the most important parameter and specifies the application of your model,\n",
        "regression: regression\n",
        "binary: binary classification\n",
        "multiclass: multiclass classification\n",
        "\n",
        "\n",
        "* boosting: defines the type of algorithm you want to run, default=gdbt\n",
        "gbdt: traditional Gradient Boosting Decision Tree\n",
        "rf: random forest\n",
        "dart: Dropouts meet Multiple Additive Regression Trees\n",
        "goss: Gradient-based One-Side Sampling\n",
        "\n",
        "* learning_rate:  the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function. Typical values: 0.1, 0.001, 0.003.\n",
        "\n",
        "\n",
        "* num_leaves: number of leaves in full tree, default: 31\n",
        "\n",
        "* device: cpu, gpu, default is cpu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AxsR_m4TnUg"
      },
      "source": [
        "### **Classification Evaluation Metrics**\n",
        "\n",
        "Classification evaluation metrics are used to evaluate the performance of a machine learning model that is trained for classification tasks. Some of the commonly used classification evaluation metrics are F1 score, recall score, confusion matrix, and ROC AUC score. Here's an overview of each of these metrics:\n",
        "\n",
        "**F1 score**: The F1 score is a metric that combines the precision and recall of a model into a single value. It is calculated as the harmonic mean of precision and recall, and is expressed as a value between 0 and 1, where 1 indicates perfect precision and recall. \n",
        "F1 score is the harmonic mean of precision and recall. It is calculated as follows:\n",
        "$$ F1 = \\frac{2}{\\frac{1}{precision} + \\frac{1}{recall}} $$\n",
        "where precision is the number of true positives divided by the sum of true positives and false positives, and recall is the number of true positives divided by the sum of true positives and false negatives.\n",
        "\n",
        "**Recall**: Use the recall score when the cost of false negatives (i.e., missing instances of a class) is high. For example, in a medical diagnosis problem, the cost of missing a positive case may be high, so recall would be a more appropriate metric.\n",
        "Recall score (also known as sensitivity) is the number of true positives divided by the sum of true positives and false negatives. It is given by the following formula:\n",
        "$$ Recall = \\frac{TP}{TP + FN} $$\n",
        "\n",
        "**Precision**: Precision is another important classification evaluation metric, which is defined as the ratio of true positives to the total predicted positives. It measures the accuracy of positive predictions made by the classifier, i.e., the proportion of positive identifications that were actually correct.\n",
        "The formula for precision is:\n",
        "$$ precision = \\frac{true\\ positive}{true\\ positive + false\\ positive} $$\n",
        "where true positive refers to the cases where the model correctly predicted the positive class, and false positive refers to the cases where the model incorrectly predicted the positive class.\n",
        "Precision is useful when the cost of false positives is high, such as in medical diagnosis or fraud detection, where a false positive can have serious consequences. In such cases, a higher precision indicates that the model is better at identifying true positives and minimizing false positives.\n",
        "\n",
        "**Confusion Matrix**:\n",
        "A confusion matrix is a table that is often used to describe the performance of a classification model. It compares the predicted labels with the true labels and counts the number of true positives, false positives, true negatives, and false negatives. Here is an example of a confusion matrix:\n",
        "\n",
        "|          | Actual Positive | Actual Negative |\n",
        "|----------|----------------|----------------|\n",
        "| Predicted Positive | True Positive (TP) | False Positive (FP) |\n",
        "| Predicted Negative | False Negative (FN) | True Negative (TN) |\n",
        "\n",
        "​\n",
        " \n",
        "\n",
        "\n",
        "**ROC AUC Score**:\n",
        "ROC AUC (Receiver Operating Characteristic Area Under the Curve) score is a measure of how well a classifier is able to distinguish between positive and negative classes. It is calculated as the area under the ROC curve. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. TPR is the number of true positives divided by the sum of true positives and false negatives, and FPR is the number of false positives divided by the sum of false positives and true negatives.\n",
        "$$ ROC\\ AUC\\ Score = \\int_0^1 TPR(FPR^{-1}(t)) dt $$\n",
        "where $FPR^{-1}$ is the inverse of the FPR function.\n",
        "\n",
        "**When to use which**:\n",
        "\n",
        "The choice of evaluation metric depends on the specific requirements of the business problem. Here are some general guidelines:\n",
        "\n",
        "* F1 score: Use the F1 score when the class distribution is imbalanced, and when both precision and recall are equally important.\n",
        "\n",
        "* Recall score: Use the recall score when the cost of false negatives (i.e., missing instances of a class) is high. For example, in a medical diagnosis problem, the cost of missing a positive case may be high, so recall would be a more appropriate metric.\n",
        "\n",
        "* Precision: Precision is useful when the cost of false positives is high, such as in medical diagnosis or fraud detection, where a false positive can have serious consequences. In such cases, a higher precision indicates that the model is better at identifying true positives and minimizing false positives.\n",
        "\n",
        "* Confusion matrix: The confusion matrix is a versatile tool that can be used to visualize the performance of a model across different classes. It can be useful for identifying specific areas of the model that need improvement.\n",
        "\n",
        "* ROC AUC score: Use the ROC AUC score when the ability to distinguish between positive and negative classes is important. For example, in a credit scoring problem, the ability to distinguish between good and bad credit risks is crucial.\n",
        "\n",
        "Importance with respect to the business problem:\n",
        "\n",
        "The importance of each evaluation metric varies depending on the business problem. For example, in a spam detection problem, precision may be more important than recall, since false positives (i.e., classifying a non-spam email as spam) may annoy users, while false negatives (i.e., missing a spam email) may not be as harmful. On the other hand, in a disease diagnosis problem, recall may be more important than precision, since missing a positive case (i.e., a false negative) could have serious consequences. Therefore, it is important to choose the evaluation metric that is most relevant to the specific business problem at hand.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhtmEHdre5RD"
      },
      "source": [
        "## **Difference between Multiclass and Multilabel Classification**\n",
        "\n",
        "Multi-class classification refers to a classification task where the goal is to assign an input data point to one of several pre-defined categories. In multi-class classification, each data point can belong to only one class. Examples of multi-class classification tasks include digit recognition, where the goal is to identify handwritten digits from 0-9, or image classification, where the task is to classify images into different categories such as animals, plants, or buildings.\n",
        "\n",
        "On the other hand, multi-label classification refers to a classification task where the goal is to assign one or more labels to each input data point. In multi-label classification, each data point can belong to multiple classes. Examples of multi-label classification tasks include text categorization, where a given document can belong to multiple categories such as politics, sports, or entertainment, or image tagging, where an image can be tagged with multiple labels such as \"beach,\" \"sunset,\" \"ocean,\" etc.\n",
        "\n",
        "When dealing with multilabel classification problems, we have several approaches we can use to handle the problem.\n",
        "\n",
        "The first approach is the naive independent models approach. In this approach, we build separate models for each label and combine their predictions to determine the appropriate mode of transport. For example, we can train one model to predict whether a product will be transported by air, another model to predict whether it will be transported by road, and so on. The predictions of these models can then be combined to determine the final mode of transport.\n",
        "\n",
        "The second approach is the classifier chains approach. In this approach, we use a chain of classifiers, where the output of one classifier is fed into the next classifier to predict the labels. For example, we can train a model to predict whether a product will be transported by air, and then use the output of this model as an input to another model that predicts whether it will be transported by road, and so on.\n",
        "\n",
        "The third approach is the natively multilabel models approach. In this approach, we use models designed to handle multilabel classification tasks, such as Extra Trees and Neural Networks. These models are trained to predict multiple labels simultaneously. The models predict the probability of each label being present in the input. The model outputs a set of predicted probabilities for each label, and a threshold is used to determine which labels to assign to the input.\n",
        "\n",
        "The fourth approach is the multilabel to multiclass approach. In this approach, we convert the multilabel problem into a multiclass problem by combining different combinations of labels and training the model to predict these combinations. After prediction, we separate the combinations back into individual labels. For example, we can train a model to predict whether a product will be transported by air and road, air and rail, road and rail, and so on. The model can then predict one of these combinations, which can be separated back into individual labels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUKHVZ4Mry1U"
      },
      "source": [
        "\\begin{array}{ccc}\n",
        "\\text{Method}&\\text{Any Model}&\\text{Num Models}&\\text{Cross-information}&\\text{Order independent}&\\text{Scale well}\\\\\n",
        "Independent & ✔️ & N & ❌ & ✔️ & ✔️ \\\\\n",
        "Chain       & ✔️ & N & ✔️ & ❌ & ✔️ \\\\\n",
        "Native      & ❌ & 1 & ✔️ & ✔️ & ✔️ \\\\\n",
        "Multiclass  & ✔️ & 1 & ✔️ & ✔️ & ❌ \\\\\n",
        "\\end{array}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv9tEqvVm29W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection, multioutput, metrics\n",
        "import lightgbm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dNwI-WhnJG9"
      },
      "source": [
        "### **Cross Validation**\n",
        "\n",
        "Cross-validation is a technique used in machine learning to evaluate the performance of a model on unseen data. The main idea behind cross-validation is to split the available data into subsets for training and testing, ensuring that the model is tested on data that it has not seen before.\n",
        "\n",
        "The most common type of cross-validation is k-fold cross-validation, where the data is divided into k equally-sized subsets or folds. The model is trained on k-1 of these folds and tested on the remaining fold. This process is repeated k times, with each fold being used as the test set once. The performance of the model is then averaged across all k folds to obtain an estimate of how well the model will generalize to new data.\n",
        "\n",
        "Cross-validation is done to prevent overfitting, which occurs when a model learns to fit the training data too well and fails to generalize to new data. By using cross-validation, we can get an estimate of how well the model will perform on new data, and can tune the model parameters accordingly to improve its performance.\n",
        "\n",
        "Cross-validation is also useful when the dataset is small, as it allows us to make better use of the available data by using each sample for both training and testing. It can also be used to compare the performance of different models or algorithms on the same dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nne8h4-wo_nA"
      },
      "outputs": [],
      "source": [
        "x = s.drop(columns=labels).astype(\"float32\")\n",
        "y = s[labels]\n",
        "\n",
        "cv_folds = list(model_selection.KFold(n_splits=5, shuffle=True, random_state=42).split(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PRpfvIteleT"
      },
      "source": [
        "### **Approach 0: Independent models**\n",
        "\n",
        "The independent models approach is a method used in multilabel classification tasks, where each label is treated as a separate binary classification problem. In this approach, independent models are trained for each label separately, and the predictions from all the models are combined to predict the final set of labels for a given input.\n",
        "\n",
        "The process of training independent models is straightforward. Each label is treated as the target variable, and the remaining variables in the dataset are used as input features. A binary classification model is then trained for each label using the appropriate algorithm and hyperparameters. Once all the models have been trained, they are used to predict the labels for the test set.\n",
        "\n",
        "The final prediction is obtained by combining the predictions of all the models.\n",
        "\n",
        "One advantage of the independent models approach is that it is simple to implement. However, it does not take into account any dependencies that may exist between the labels. Additionally, it may not perform as well as other methods in situations where the labels are highly correlated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFLFxROLoTXO"
      },
      "source": [
        "This code below is implementing the independent models approach using LightGBM as the base classifier. It is using cross-validation to evaluate the performance of the model on the data.\n",
        "\n",
        "The cv_folds variable contains the indices of the training and validation folds. The code then iterates over each fold and trains a separate model on each fold using the multioutput.MultiOutputClassifier wrapper. This wrapper allows us to train multiple independent models, one for each label.\n",
        "\n",
        "The model is then trained using the training data from the current fold, and the predict method is used to generate predictions on the validation data. The f1_score function from the metrics module is used to calculate the F1 score for each label separately. The F1 score is a commonly used metric for evaluating the performance of multilabel classifiers.\n",
        "\n",
        "The average F1 score across all labels is then calculated and appended to the _scores list. The fold index and the average F1 score for that fold are then printed to the console.\n",
        "\n",
        "After all the folds have been processed, the code calculates and prints the mean F1 score across all folds. This provides an estimate of the overall performance of the model on the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RczjMCuOxG3F",
        "outputId": "f5137f43-a48f-4d39-f1ba-c3155c2dbc7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t0.8207\n",
            "1\t0.8442\n",
            "2\t0.8151\n",
            "3\t0.8356\n",
            "4\t0.8220\n",
            "--------------\n",
            " \t0.8275\n"
          ]
        }
      ],
      "source": [
        "# Initialize an empty list to store f1 scores for each fold\n",
        "_scores = []\n",
        "preserve(\"715840\")\n",
        "# Iterate through each fold using its index and the corresponding training/validation indices\n",
        "for fold_idx, (idxT, idxV) in enumerate(cv_folds):\n",
        "\n",
        "    # Define a multioutput classifier model using LGBMClassifier with a random seed of 42\n",
        "    model = multioutput.MultiOutputClassifier(lightgbm.LGBMClassifier(random_seed=42))\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(x.iloc[idxT], y.iloc[idxT])\n",
        "    \n",
        "    # Generate predictions using the validation data\n",
        "    p = model.predict(x.iloc[idxV])\n",
        "\n",
        "    # Calculate the average f1 score for each label using the validation data and the corresponding predictions\n",
        "    avg_f1_score = np.mean([metrics.f1_score(y.iloc[idxV].iloc[:, i].to_numpy().astype(int), p[:, i].astype(int)) for i in range(4)])\n",
        "\n",
        "    # Append the average f1 score to the scores list\n",
        "    _scores.append(avg_f1_score)\n",
        "\n",
        "    # Print the fold index and the average f1 score\n",
        "    print(\"%d\\t%.4f\" % (fold_idx, avg_f1_score))\n",
        "\n",
        "# Print the mean f1 score across all folds    \n",
        "print(\"--------------\")\n",
        "print(\" \\t%.4f\" % np.mean(_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKJ0BMnPewle"
      },
      "source": [
        "### **Approach 1: Classifier chain**\n",
        "\n",
        "Classifier Chains is an approach used for multilabel classification problems. It involves creating a chain of classifiers that are trained in a specific order based on label dependencies. In this approach, the output of one classifier is fed into the next classifier to predict the labels. The chain of classifiers can be created in various ways such as based on label dependencies, using a random order, or using a pre-defined order.\n",
        "\n",
        "The Classifier Chains approach can be useful when there are correlations between labels, as it allows the model to consider these correlations when making predictions. However, it can also result in the propagation of errors from one classifier to the next, which can negatively impact the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKFK_yNVy9T0",
        "outputId": "58d060cd-f305-4e9b-b73f-e49cb0369f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t0.8105 | 0.8158 0.8105 0.8190\n",
            "1\t0.8397 | 0.8408 0.8372 0.8426\n",
            "2\t0.8091 | 0.8086 0.8099 0.8116\n",
            "3\t0.8330 | 0.8303 0.8282 0.8282\n",
            "4\t0.8261 | 0.8227 0.8227 0.8270\n",
            "--------------\n",
            " \t0.8237\n"
          ]
        }
      ],
      "source": [
        "_scores = []  # create a list to store F1 scores for each fold\n",
        "\n",
        "for fold_idx, (idxT, idxV) in enumerate(cv_folds):  # iterate through each fold\n",
        "    p_list = []  # create a list to store predictions for each repetition\n",
        "    avg_f1_score_list = []  # create a list to store F1 scores for each repetition\n",
        "\n",
        "    for rep in range(3):  # repeat the process 3 times\n",
        "        # create a Classifier Chain model with LightGBM as the base classifier\n",
        "        model = multioutput.ClassifierChain(lightgbm.LGBMClassifier(random_seed=42), order=\"random\", cv=5)\n",
        "        # fit the model on training data\n",
        "        model.fit(x.iloc[idxT].fillna(0.0), y.iloc[idxT])\n",
        "        # make predictions on validation data\n",
        "        p_rep = model.predict(x.iloc[idxV].fillna(0.0))\n",
        "        # store predictions and F1 score for each repetition\n",
        "        p_list.append(p_rep)\n",
        "        avg_f1_score_list.append(np.mean([metrics.f1_score(y.iloc[idxV].iloc[:, i].to_numpy().astype(int), p_rep[:, i].astype(int)) for i in range(4)]))\n",
        "    \n",
        "    # calculate average predictions and F1 score across repetitions\n",
        "    p = np.stack(p_list, axis=0).mean(0)\n",
        "    avg_f1_score = np.mean([metrics.f1_score(y.iloc[idxV].iloc[:, i].to_numpy().astype(int), p[:, i].astype(int)) for i in range(4)])\n",
        "    _scores.append(avg_f1_score)\n",
        "    # print fold index and F1 scores for each repetition and overall F1 score for the fold\n",
        "    print(\"%d\\t%.4f | %.4f %.4f %.4f\" % (fold_idx, avg_f1_score, avg_f1_score_list[0], avg_f1_score_list[1], avg_f1_score_list[2]))\n",
        "    \n",
        "model_snapshot(\"715840\") \n",
        "# print the mean F1 score across all folds\n",
        "print(\"--------------\")\n",
        "print(\" \\t%.4f\" % np.mean(_scores))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYZS0eZae9xM"
      },
      "source": [
        "### **Approach 2: Natively Multilabel Models**\n",
        "\n",
        "Natively multilabel models are specifically designed to handle multilabel classification tasks. These models are different from multiclass classification models, which are designed to classify samples into a single class among multiple possible classes.\n",
        "\n",
        "One advantage of natively multilabel models is that they can handle high-dimensional output spaces. Also, they can handle label correlations and label dependencies, which are common in many real-world problems. However, the main drawback of these models is that they can be computationally expensive, especially for large output spaces.\n",
        "\n",
        "Natively multilabel models predict the probability of each label being present in the output. For example, in a multilabel classification problem with three possible labels, the model might output [0.8, 0.3, 0.6], indicating that label 1 has an 80% chance of being present, label 2 has a 30% chance, and label 3 has a 60% chance. The model will make a prediction for each label based on a threshold value. If the predicted probability of a label is above the threshold, it will be considered present in the output, and if it is below the threshold, it will be considered absent. The threshold value is usually set based on a trade-off between precision and recall. A higher threshold value will lead to higher precision (fewer false positives) but lower recall (more false negatives), while a lower threshold value will lead to higher recall (fewer false negatives) but lower precision (more false positives)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5ABIwtUBseo"
      },
      "source": [
        "### **Extra Trees Classifier**\n",
        "\n",
        "Extra Trees, also known as Extremely Randomized Trees, is an ensemble learning method that combines multiple decision trees to improve prediction accuracy and reduce overfitting. The method is similar to Random Forests, but with a few key differences.\n",
        "\n",
        "Random Forest builds each decision tree using a subset of features selected randomly for each split. This process is known as \"feature bagging\" or \"random subspace method\". The algorithm then selects the best split among a random subset of features at each node of the decision tree.\n",
        "\n",
        "On the other hand, Extra Trees builds each decision tree using the entire set of features, without performing feature selection. Moreover, instead of finding the best split among a random subset of features at each node, Extra Trees selects the split point randomly for each feature, and chooses the one that minimizes the impurity of the split.\n",
        "\n",
        "These differences motivate the reduction of both bias and variance. On one hand, using the whole original sample instead of a bootstrap replica will reduce bias. On the other hand, choosing randomly the split point of each node will reduce variance.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ElWvIoTfuh3",
        "outputId": "7824b6e9-23a2-482d-ec94-6b6344193460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t0.8062\n",
            "1\t0.8259\n",
            "2\t0.7810\n",
            "3\t0.8118\n",
            "4\t0.8043\n",
            "--------------\n",
            " \t0.8058\n"
          ]
        }
      ],
      "source": [
        "from sklearn import ensemble\n",
        "\n",
        "_scores = [] # initialize a list to store f1 score of each fold\n",
        "\n",
        "# loop over each fold of the cross-validation\n",
        "for fold_idx, (idxT, idxV) in enumerate(cv_folds):\n",
        "    \n",
        "    # initialize an ExtraTreesClassifier model\n",
        "    model = ensemble.ExtraTreesClassifier()\n",
        "    \n",
        "    # fit the model on training data and target labels\n",
        "    model.fit(x.iloc[idxT].fillna(-100), y.iloc[idxT])\n",
        "    \n",
        "    # predict the target labels on validation data\n",
        "    p = model.predict(x.iloc[idxV].fillna(-100))\n",
        "    \n",
        "    # calculate f1 score for each label and take average\n",
        "    avg_f1_score = np.mean([metrics.f1_score(y.iloc[idxV].iloc[:, i].to_numpy().astype(int), p[:, i].astype(int)) for i in range(4)])\n",
        "    \n",
        "    # append the f1 score to the list\n",
        "    _scores.append(avg_f1_score)\n",
        "    \n",
        "    # print the f1 score of each fold\n",
        "    print(\"%d\\t%.4f\" % (fold_idx, avg_f1_score))\n",
        "\n",
        "# print the mean f1 score across all folds\n",
        "print(\"--------------\")\n",
        "print(\" \\t%.4f\" % np.mean(_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOZNUFqbnlyx"
      },
      "source": [
        "### **Neural Networks**\n",
        "\n",
        "Neural networks, also known as artificial neural networks, are a type of machine learning algorithm inspired by the structure and function of the human brain. They are composed of interconnected nodes, or artificial neurons, that are organized into layers to process and analyze data.\n",
        "\n",
        "The structure of a neural network typically includes an input layer, one or more hidden layers, and an output layer. The input layer is where data is fed into the network, and the output layer produces the final output of the network. The hidden layers are where the majority of the processing takes place and where the neural network learns to identify patterns and make predictions.\n",
        "\n",
        "Each node in a neural network takes input data, processes it, and produces an output signal that is passed on to other nodes in the network. The processing that occurs within a node is typically composed of two parts: a linear transformation and a nonlinear activation function.\n",
        "\n",
        "The linear transformation is simply a weighted sum of the inputs to the node, where each input is multiplied by a corresponding weight. The weights determine the strength of the connection between the input and the node and are learned by the neural network during the training process.\n",
        "\n",
        "The output of the linear transformation is then passed through a nonlinear activation function, which is used to introduce nonlinearity into the neural network. Nonlinearity is important because many real-world problems are inherently nonlinear, and a neural network without nonlinear activation functions would be limited in its ability to model these problems.\n",
        "\n",
        "There are many different types of activation functions used in neural networks, including sigmoid, tanh, ReLU (Rectified Linear Unit), and softmax. Each activation function has its own strengths and weaknesses and is chosen based on the specific requirements of the problem being solved.\n",
        "\n",
        "During the training process, the neural network is fed input data along with corresponding output data, and the weights between the nodes are adjusted to minimize the difference between the network's predictions and the actual output. This process is known as backpropagation, and it uses an optimization algorithm such as gradient descent to iteratively adjust the weights until the network produces accurate predictions.\n",
        "\n",
        "Once the neural network has been trained, it can be used to make predictions on new, unseen data. The input data is fed into the network, and the output of the final layer represents the network's prediction for that input.\n",
        "\n",
        "#### **Activation Functions**\n",
        "\n",
        "Activation functions are one of the crucial components of neural networks. They introduce nonlinearity to the model, allowing it to approximate complex functions. Activation functions apply a mathematical operation to the weighted sum of inputs, known as the activation value, and produce an output that passes to the next layer.\n",
        "\n",
        "The role of activation functions is to introduce non-linearity into the output of a neuron. Without non-linearity, the model would be limited to linear transformations of the input. As a result, the output would be a linear function of the input, which is not suitable for many real-world problems that are highly non-linear in nature.\n",
        "\n",
        "There are several types of activation functions, some of which are as follows:\n",
        "\n",
        "* Sigmoid Function: The sigmoid function is one of the oldest activation functions and is still used today. The sigmoid function maps any input to a value between 0 and 1. The sigmoid function is often used in binary classification problems, where the output is either 0 or 1. The sigmoid function is defined as:\n",
        "$$f(x) = \\frac{1}{1 + e^{-x}}$$\n",
        "where z is the input to the sigmoid function.\n",
        "\n",
        "* ReLU (Rectified Linear Unit) Function: The ReLU function is one of the most widely used activation functions. The ReLU function sets any negative value in the input to zero and leaves the positive values unchanged. The ReLU function is defined as:\n",
        "$$f(z) = \\max(0, z)$$\n",
        "where z is the input to the ReLU function.\n",
        "\n",
        "* Leaky ReLU Function: Leaky ReLU (Rectified Linear Unit) is a type of activation function used in neural networks. It is similar to the standard ReLU function but with a small modification to address a limitation of the standard ReLU function.\n",
        "The standard ReLU function returns 0 for any negative input and a linear output for positive inputs. However, the problem with the standard ReLU function is that when the input is negative, the gradient of the function is 0, which can lead to a problem known as \"dying ReLU.\" This occurs when the weights in the network become so large that the inputs to the ReLU function are always negative, causing the gradients to be 0 and the weights to stop updating during training.\n",
        "Leaky ReLU addresses this problem by adding a small slope to the negative part of the function. Specifically, the function returns the input if it is positive, but returns a small fraction (often 0.01) of the input if it is negative. This ensures that the function always has a gradient and prevents the \"dying ReLU\" problem.\n",
        "$$f(z) = \\max(0.01z, z)$$\n",
        "where z is the input to the leaky ReLU function. The leaky ReLU function is often used when the ReLU function fails to provide good results.\n",
        "\n",
        "* Softmax Function: The softmax function is often used in multi-class classification problems, where the output is one of several classes. The softmax function maps the input to a probability distribution over the output classes. The softmax function is defined as:\n",
        "$$f(x_i) = \\frac{e^{x_i}}{\\sum_{j=1}^{k}e^{x_j}}$$\n",
        "where $k$ is the number of classes and $x_i$ is the input to the $i$-th class\n",
        "\n",
        "There are two main stages in the training of neural networks: forward propagation and backpropagation. In forward propagation, the input data is passed through the network to generate a prediction or output. In backpropagation, the error in the prediction is calculated and used to update the weights of the network. This process is repeated iteratively until the error is minimized.\n",
        "\n",
        "**Forward Propagation**:\n",
        "\n",
        "In forward propagation, the input data is passed through the network from the input layer to the output layer. Each layer in the network consists of a set of nodes, or neurons, which perform a simple computation on their inputs. The output of one layer is fed as input to the next layer until the final output is produced.\n",
        "\n",
        "The computation performed by each neuron is based on the activation function applied to the weighted sum of its inputs. The activation function is used to introduce non-linearity into the network, allowing it to model more complex relationships between the input and output data.\n",
        "\n",
        "**Backpropagation**:\n",
        "\n",
        "In backpropagation, the error in the prediction is calculated and used to update the weights of the network. The error is typically measured using a loss function, which compares the predicted output with the actual output. The goal of backpropagation is to minimize the loss function by adjusting the weights of the network.\n",
        "\n",
        "The process of backpropagation involves calculating the derivative of the loss function with respect to the weights of the network. This derivative is then used to update the weights of the network in the opposite direction of the gradient, in order to minimize the loss function.\n",
        "\n",
        "**Optimizers**:\n",
        "\n",
        "Optimizers are algorithms used to update the weights of the neural network during the backpropagation process. They are used to find the optimal set of weights that minimize the loss function. There are several different types of optimizers available, each with its own strengths and weaknesses. Some common optimizers include:\n",
        "\n",
        "* Gradient Descent: Gradient descent is a simple optimizer that works by adjusting the weights of the network in the direction of the negative gradient of the loss function. It is a first-order optimization method and is often used as a baseline for more complex optimizers.\n",
        "\n",
        "* Stochastic Gradient Descent (SGD): SGD is a variant of gradient descent that updates the weights using a small batch of data at a time, rather than the entire dataset. This can lead to faster convergence and better generalization.\n",
        "\n",
        "* Adam: Adam is an adaptive optimizer that adjusts the learning rate based on the gradient variance and moving average of the gradients. It is an effective optimizer for a wide range of neural network architectures and is widely used in practice.\n",
        "\n",
        "* RMSProp: RMSProp is an adaptive optimizer that uses a moving average of the squared gradients to adjust the learning rate. It is effective for dealing with noisy gradients and is widely used in deep learning.\n",
        "\n",
        "### **Techniques to Counter Overfitting**\n",
        "\n",
        "Overfitting is a common problem in neural networks, which occurs when a model becomes too complex and starts to memorize the training data rather than learning the underlying patterns. This leads to poor generalization performance on new data. There are several techniques to counter overfitting in neural networks, some of which are:\n",
        "\n",
        "* Dropout: Dropout is a technique where a random selection of neurons are ignored during training. This technique helps to prevent overfitting by reducing the complex co-adaptations that can occur between neurons. Dropout randomly selects a fraction of the nodes in a layer and sets their output to zero during training. This makes the network more robust and prevents overfitting.\n",
        "\n",
        "* Data Augmentation: Data augmentation is a technique where we artificially increase the size of our training data by applying various transformations to the data. This helps to prevent overfitting by providing the model with more diverse examples to learn from. Data augmentation can include techniques like flipping, rotation, scaling, cropping, and color jittering.\n",
        "\n",
        "* Early Stopping: Early stopping is a technique where we stop training the model as soon as the performance on the validation data starts to deteriorate. This helps to prevent overfitting by preventing the model from overfitting to the training data. The idea behind early stopping is to stop training before the model starts to memorize the training data and starts to perform poorly on unseen data.\n",
        "\n",
        "* Regularization: Regularization is a technique where we add a penalty term to the loss function to prevent the model from overfitting. This is typically achieved by adding an L1 or L2 penalty term to the weights of the model. L1 regularization adds a penalty proportional to the absolute value of the weights while L2 regularization adds a penalty proportional to the square of the weights.\n",
        "\n",
        "* Batch Normalization: Batch normalization is a technique where we normalize the inputs to a layer to have zero mean and unit variance. This helps to prevent overfitting by reducing the internal covariate shift in the model. Internal covariate shift is when the distribution of inputs to a layer changes during training, which can make it difficult for the model to learn.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrIQ3cCQF51E"
      },
      "source": [
        "### **Sequential Layering**\n",
        "\n",
        "Sequential model building involves stacking multiple layers one after the other to form a feed-forward network. This architecture is also referred to as a multi-layer perceptron (MLP).\n",
        "\n",
        "In the given code, we start by importing the necessary libraries, including TensorFlow and Keras, which are the primary deep learning libraries. We also import TensorFlow Addons, which provides additional functionality to TensorFlow. We then split the data into training and validation sets using K-fold cross-validation, where we use a fraction of the data for training and the rest for validation.\n",
        "\n",
        "Next, we define the architecture of our neural network by creating an instance of a sequential model using the Keras Sequential API. The sequential model is a linear stack of layers, where each layer has an input and an output. The first layer in our model is the normalization layer, which normalizes the input data. We then add three dense layers with ReLU activation and dropout layers in between them to prevent overfitting. The last layer is a dense layer with a sigmoid activation function since we are dealing with binary classification. We then compile the model by specifying the optimizer and loss function.\n",
        "\n",
        "After compiling the model, we train it using the training data and validate it using the validation data. We train the model for 50 epochs, with a batch size of 32, and evaluate its performance by plotting the training and validation loss. Finally, we predict the labels for the validation data using the trained model and calculate the average F1 score as a performance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "753yP_ZT0FCs",
        "outputId": "2454bca2-5bae-4fd2-ddcc-30d61aff7a33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\t0.7473\n",
            "1\t0.7587\n",
            "2\t0.7472\n",
            "3\t0.7432\n",
            "4\t0.7603\n",
            "--------------\n",
            " \t0.7514\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_scores = []\n",
        "for fold_idx, (idxT, idxV) in enumerate(cv_folds):\n",
        "    norm = keras.layers.Normalization()\n",
        "    norm.adapt(x.iloc[idxT].fillna(0.0))\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        norm,\n",
        "        keras.layers.Dense(512, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(256, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(y.shape[-1])\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(5e-4),\n",
        "        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    )\n",
        "\n",
        "    x_train = x.iloc[idxT].fillna(0.0).values.astype('float32')\n",
        "    y_train = y.iloc[idxT].values.astype('int32')\n",
        "    x_valid = x.iloc[idxV].fillna(0.0).values.astype('float32')\n",
        "    y_valid = y.iloc[idxV].values.astype('int32')\n",
        "\n",
        "    hist = model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=50, batch_size=32, verbose=0)\n",
        "    plt.plot(hist.history['loss'], color='tab:blue')\n",
        "    plt.plot(hist.history['val_loss'], color='tab:red')\n",
        "\n",
        "    p_valid = model.predict(x_valid, verbose=0)\n",
        "    p_valid = (p_valid > 0.0).astype(int)\n",
        "    avg_f1_score = np.mean([metrics.f1_score(y.iloc[idxV].iloc[:, i].to_numpy().astype(int), p_valid[:, i].astype(int)) for i in range(4)])\n",
        "    _scores.append(avg_f1_score)\n",
        "    print(\"%d\\t%.4f\" % (fold_idx, avg_f1_score))\n",
        "\n",
        "model_snapshot(\"715840\")\n",
        "print(\"--------------\")\n",
        "print(\" \\t%.4f\" % np.mean(_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wyWrBqdfCsd"
      },
      "source": [
        "### **Approach 3: Multilabel to Multiclass**\n",
        "\n",
        "Multilabel classification refers to the task of assigning multiple labels to a single instance. For instance, in the case of an image classification problem, an image can be associated with more than one label. On the other hand, multiclass classification refers to the task of assigning a single label to each instance. For instance, in an image classification problem, an image can only be associated with one label.\n",
        "\n",
        "In some cases, it may be more appropriate to convert a multilabel classification problem into a multiclass classification problem. This can be done by converting each unique combination of labels into a separate class. The advantage of this approach is that it allows the use of standard classification algorithms that are designed for multiclass classification problems.\n",
        "\n",
        "Now, let's consider the below code. The first section of the code is converting the multi-label encoded data to multi-class encoded data. It does this by first creating a copy of the original target variable y and then concatenating each row's values using a hyphen (-) separator. This concatenated string is then used as a unique code to identify each combination of the target variable's binary labels. The function drop_duplicates() removes the duplicate codes, and np.arange(y_codes.shape[0]) generates a sequence of integers from 0 to the number of unique codes. These unique codes are then merged back into the original target variable y using the merge() function to replace the binary labels with unique integers.\n",
        "\n",
        "The second section of the code is training and evaluating a multi-class classification model using the LightGBM algorithm. The model is trained and validated using k-fold cross-validation, where cv_folds are the indices of the training and validation sets for each fold.  After training the model, it generates predictions on the validation set using the predict() function. The predicted integer values are then converted back into the original binary label format using the unique codes generated earlier. Finally, the mean F1 score for each fold is computed and printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KR0BOuVqPgw",
        "outputId": "8d95f4dc-7fc8-4782-a2cb-ef092b47f602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15 classes\n",
            "0\t0.7938\n",
            "1\t0.8048\n",
            "2\t0.7783\n",
            "3\t0.8023\n",
            "4\t0.8001\n",
            "--------------\n",
            " \t0.7959\n"
          ]
        }
      ],
      "source": [
        "y_ = y.copy()\n",
        "y_['code'] = y.apply(lambda x: '-'.join([str(xi) for xi in x]), axis=1)\n",
        "y_codes = y_.drop_duplicates()\n",
        "y_codes['idx'] = np.arange(y_codes.shape[0])\n",
        "y_class = y_.merge(y_codes, on='code', how='left')['idx']\n",
        "print(f\"{y_codes.shape[0]} classes\")\n",
        "\n",
        "_scores = []\n",
        "for fold_idx, (idxT, idxV) in enumerate(cv_folds):\n",
        "    model = lightgbm.LGBMClassifier(random_seed=42)\n",
        "    model.fit(x.iloc[idxT], y_class.iloc[idxT])\n",
        "\n",
        "    p = model.predict(x.iloc[idxV])\n",
        "    p = pd.DataFrame({'idx': p}).merge(y_codes, on='idx', how='left')[labels]\n",
        "    avg_f1_score = np.mean([metrics.f1_score(y.iloc[idxV].iloc[:, i].to_numpy().astype(int), p.iloc[:, i].astype(int)) for i in range(4)])\n",
        "    _scores.append(avg_f1_score)\n",
        "    print(\"%d\\t%.4f\" % (fold_idx, avg_f1_score))\n",
        "\n",
        "model_snapshot(\"715840\")\n",
        "print(\"--------------\")\n",
        "print(\" \\t%.4f\" % np.mean(_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vahixjQWHkry"
      },
      "source": [
        "## **Try it out - I**\n",
        "\n",
        "* Write python codes for different data preprocessing techniques and do a thorough data analysis.\n",
        "\n",
        "* Try using different base classifiers such as Support Vector Machines (SVMs), Random Forests, or Gradient Boosting Machines (GBMs) and compare the difference in the performance metrics.\n",
        "\n",
        "**Optional**:\n",
        "\n",
        "Create a pipeline in Scikit-Learn to perform the following steps on the given dataset in python:\n",
        "\n",
        "* Load the dataset\n",
        "* Preprocess the data by encoding categorical variables and handling missing values.\n",
        "* Split the data into training and testing sets\n",
        "* Train and evaluate the performance of a multiclass classification model using the Independent Models approach with different base models.\n",
        "* Train and evaluate the performance of a multiclass classification model using the Chain Classifier approach with different base models.\n",
        "* Experiment with Hyperparameters.\n",
        "* Compare the performance and determine which approach performs better on the given dataset.\n",
        "\n",
        "Hint: You can use Scikit-Learn's Pipeline and GridSearchCV classes to create and optimize the pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjF5SoczJ6NZ"
      },
      "source": [
        "## **Conclusion**\n",
        "\n",
        "In this project, we explored different approaches to handle multilabel classification problems. We started with exploratory data analysis to understand the features and check for missing or invalid values. Then, we preprocessed the data by encoding categorical features and splitting the dataset into training and testing sets.\n",
        "\n",
        "Next, we created cross-validation sets and evaluated the performance of four different approaches to handle multilabel classification problems. The first approach was to train separate binary classifiers for each target label, followed by the classifier chains approach where we chained the classifiers together to consider the dependencies between labels. Then, we explored natively multilabel models such as Extra Trees and Neural Networks. Finally, we combined different combinations of labels into a single target label and trained a lightgbm classifier on the combined labels.\n",
        "\n",
        "This project highlights the importance of choosing an appropriate approach when dealing with multilabel classification problems. While the Naive Independent Models approach is simple to implement. The Classifier Chains approach takes into account the dependencies between labels and can improve model performance. The Natively Multilabel Models approach is specifically designed for multilabel classification problems and can further improve performance. \n",
        "\n",
        "As observed in the project, the independent model approach performed better compared to the other approaches for this particular dataset. This can be attributed to the fact that the target labels in this dataset, such as sea, air, and road, are relatively independent of each other.\n",
        "\n",
        "Therefore, it was more effective to train separate binary classifiers for each target label instead of considering the dependencies between them. However, it is important to note that this may not always be the case for other datasets with more complex and interdependent target labels."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
